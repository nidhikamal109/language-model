{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', ' ')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    " \n",
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went down yesterday to the Piraeus with Glaucon the son of Ariston,\n",
      "that I might offer up my prayers to the goddess (Bendis, the Thracian\n",
      "Artemis.); and also because I wanted to see in what manner t\n"
     ]
    }
   ],
   "source": [
    "# load document\n",
    "in_filename = 'republic_clean.txt'\n",
    "doc = load_doc(in_filename)\n",
    "print(doc[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'went', 'down', 'yesterday', 'to', 'the', 'piraeus', 'with', 'glaucon', 'the', 'son', 'of', 'ariston', 'that', 'i', 'might', 'offer', 'up', 'my', 'prayers', 'to', 'the', 'goddess', 'bendis', 'the', 'thracian', 'artemis', 'and', 'also', 'because', 'i', 'wanted', 'to', 'see', 'in', 'what', 'manner', 'they', 'would', 'celebrate', 'the', 'festival', 'which', 'was', 'a', 'new', 'thing', 'i', 'was', 'delighted', 'with', 'the', 'procession', 'of', 'the', 'inhabitants', 'but', 'that', 'of', 'the', 'thracians', 'was', 'equally', 'if', 'not', 'more', 'beautiful', 'when', 'we', 'had', 'finished', 'our', 'prayers', 'and', 'viewed', 'the', 'spectacle', 'we', 'turned', 'in', 'the', 'direction', 'of', 'the', 'city', 'and', 'at', 'that', 'instant', 'polemarchus', 'the', 'son', 'of', 'cephalus', 'chanced', 'to', 'catch', 'sight', 'of', 'us', 'from', 'a', 'distance', 'as', 'we', 'were', 'starting', 'on', 'our', 'way', 'home', 'and', 'told', 'his', 'servant', 'to', 'run', 'and', 'bid', 'us', 'wait', 'for', 'him', 'the', 'servant', 'took', 'hold', 'of', 'me', 'by', 'the', 'cloak', 'behind', 'and', 'said', 'polemarchus', 'desires', 'you', 'to', 'wait', 'i', 'turned', 'round', 'and', 'asked', 'him', 'where', 'his', 'master', 'was', 'there', 'he', 'is', 'said', 'the', 'youth', 'coming', 'after', 'you', 'if', 'you', 'will', 'only', 'wait', 'certainly', 'we', 'will', 'said', 'glaucon', 'and', 'in', 'a', 'few', 'minutes', 'polemarchus', 'appeared', 'and', 'with', 'him', 'adeimantus', 'glaucons', 'brother', 'niceratus', 'the', 'son', 'of', 'nicias', 'and', 'several', 'others', 'who', 'had', 'been', 'at', 'the', 'procession', 'polemarchus', 'said', 'to', 'me']\n",
      "\n",
      " Total Tokens: 118682\n",
      "Unique Tokens: 7409\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:200])\n",
    "print('\\n Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 118631\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences of tokens\n",
    "length = 50 + 1\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with',\n",
       " 'went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the',\n",
       " 'down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession',\n",
       " 'yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of',\n",
       " 'to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "out_filename = 'republic_sequences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "in_filename = 'republic_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with',\n",
       " 'went down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the',\n",
       " 'down yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession',\n",
       " 'yesterday to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of',\n",
       " 'to the piraeus with glaucon the son of ariston that i might offer up my prayers to the goddess bendis the thracian artemis and also because i wanted to see in what manner they would celebrate the festival which was a new thing i was delighted with the procession of the']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11,\n",
       "  1045,\n",
       "  329,\n",
       "  7409,\n",
       "  4,\n",
       "  1,\n",
       "  2873,\n",
       "  35,\n",
       "  213,\n",
       "  1,\n",
       "  261,\n",
       "  3,\n",
       "  2251,\n",
       "  9,\n",
       "  11,\n",
       "  179,\n",
       "  817,\n",
       "  123,\n",
       "  92,\n",
       "  2872,\n",
       "  4,\n",
       "  1,\n",
       "  2250,\n",
       "  7408,\n",
       "  1,\n",
       "  7407,\n",
       "  7406,\n",
       "  2,\n",
       "  75,\n",
       "  120,\n",
       "  11,\n",
       "  1266,\n",
       "  4,\n",
       "  110,\n",
       "  6,\n",
       "  30,\n",
       "  168,\n",
       "  16,\n",
       "  49,\n",
       "  7405,\n",
       "  1,\n",
       "  1609,\n",
       "  13,\n",
       "  57,\n",
       "  8,\n",
       "  549,\n",
       "  151,\n",
       "  11,\n",
       "  57,\n",
       "  1265,\n",
       "  35],\n",
       " [1045,\n",
       "  329,\n",
       "  7409,\n",
       "  4,\n",
       "  1,\n",
       "  2873,\n",
       "  35,\n",
       "  213,\n",
       "  1,\n",
       "  261,\n",
       "  3,\n",
       "  2251,\n",
       "  9,\n",
       "  11,\n",
       "  179,\n",
       "  817,\n",
       "  123,\n",
       "  92,\n",
       "  2872,\n",
       "  4,\n",
       "  1,\n",
       "  2250,\n",
       "  7408,\n",
       "  1,\n",
       "  7407,\n",
       "  7406,\n",
       "  2,\n",
       "  75,\n",
       "  120,\n",
       "  11,\n",
       "  1266,\n",
       "  4,\n",
       "  110,\n",
       "  6,\n",
       "  30,\n",
       "  168,\n",
       "  16,\n",
       "  49,\n",
       "  7405,\n",
       "  1,\n",
       "  1609,\n",
       "  13,\n",
       "  57,\n",
       "  8,\n",
       "  549,\n",
       "  151,\n",
       "  11,\n",
       "  57,\n",
       "  1265,\n",
       "  35,\n",
       "  1]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'of': 3,\n",
       " 'to': 4,\n",
       " 'is': 5,\n",
       " 'in': 6,\n",
       " 'he': 7,\n",
       " 'a': 8,\n",
       " 'that': 9,\n",
       " 'be': 10,\n",
       " 'i': 11,\n",
       " 'not': 12,\n",
       " 'which': 13,\n",
       " 'are': 14,\n",
       " 'you': 15,\n",
       " 'they': 16,\n",
       " 'or': 17,\n",
       " 'will': 18,\n",
       " 'said': 19,\n",
       " 'as': 20,\n",
       " 'we': 21,\n",
       " 'but': 22,\n",
       " 'have': 23,\n",
       " 'them': 24,\n",
       " 'his': 25,\n",
       " 'for': 26,\n",
       " 'by': 27,\n",
       " 'who': 28,\n",
       " 'their': 29,\n",
       " 'what': 30,\n",
       " 'then': 31,\n",
       " 'this': 32,\n",
       " 'one': 33,\n",
       " 'if': 34,\n",
       " 'with': 35,\n",
       " 'there': 36,\n",
       " 'all': 37,\n",
       " 'true': 38,\n",
       " 'at': 39,\n",
       " 'when': 40,\n",
       " 'do': 41,\n",
       " 'other': 42,\n",
       " 'has': 43,\n",
       " 'yes': 44,\n",
       " 'any': 45,\n",
       " 'him': 46,\n",
       " 'no': 47,\n",
       " 'good': 48,\n",
       " 'would': 49,\n",
       " 'may': 50,\n",
       " 'state': 51,\n",
       " 'from': 52,\n",
       " 'man': 53,\n",
       " 'say': 54,\n",
       " 'our': 55,\n",
       " 'only': 56,\n",
       " 'was': 57,\n",
       " 'an': 58,\n",
       " 'must': 59,\n",
       " 'should': 60,\n",
       " 'so': 61,\n",
       " 'more': 62,\n",
       " 'us': 63,\n",
       " 'can': 64,\n",
       " 'on': 65,\n",
       " 'were': 66,\n",
       " 'very': 67,\n",
       " 'now': 68,\n",
       " 'like': 69,\n",
       " 'such': 70,\n",
       " 'replied': 71,\n",
       " 'just': 72,\n",
       " 'certainly': 73,\n",
       " 'than': 74,\n",
       " 'also': 75,\n",
       " 'these': 76,\n",
       " 'men': 77,\n",
       " 'same': 78,\n",
       " 'another': 79,\n",
       " 'about': 80,\n",
       " 'justice': 81,\n",
       " 'own': 82,\n",
       " 'how': 83,\n",
       " 'soul': 84,\n",
       " 'been': 85,\n",
       " 'let': 86,\n",
       " 'into': 87,\n",
       " 'being': 88,\n",
       " 'shall': 89,\n",
       " 'it': 90,\n",
       " 'most': 91,\n",
       " 'my': 92,\n",
       " 'me': 93,\n",
       " 'nature': 94,\n",
       " 'whether': 95,\n",
       " 'life': 96,\n",
       " 'had': 97,\n",
       " 'many': 98,\n",
       " 'those': 99,\n",
       " 'things': 100,\n",
       " 'some': 101,\n",
       " 'way': 102,\n",
       " 'mean': 103,\n",
       " 'knowledge': 104,\n",
       " 'well': 105,\n",
       " 'first': 106,\n",
       " 'your': 107,\n",
       " 'make': 108,\n",
       " 'know': 109,\n",
       " 'see': 110,\n",
       " 'her': 111,\n",
       " 'out': 112,\n",
       " 'think': 113,\n",
       " 'evil': 114,\n",
       " 'right': 115,\n",
       " 'truth': 116,\n",
       " 'himself': 117,\n",
       " 'whom': 118,\n",
       " 'sort': 119,\n",
       " 'because': 120,\n",
       " 'quite': 121,\n",
       " 'never': 122,\n",
       " 'up': 123,\n",
       " 'unjust': 124,\n",
       " 'better': 125,\n",
       " 'injustice': 126,\n",
       " 'reason': 127,\n",
       " 'others': 128,\n",
       " 'saying': 129,\n",
       " 'either': 130,\n",
       " 'therefore': 131,\n",
       " 'nothing': 132,\n",
       " 'every': 133,\n",
       " 'am': 134,\n",
       " 'two': 135,\n",
       " 'great': 136,\n",
       " 'best': 137,\n",
       " 'opinion': 138,\n",
       " 'city': 139,\n",
       " 'suppose': 140,\n",
       " 'far': 141,\n",
       " 'take': 142,\n",
       " 'ought': 143,\n",
       " 'having': 144,\n",
       " 'both': 145,\n",
       " 'question': 146,\n",
       " 'time': 147,\n",
       " 'made': 148,\n",
       " 'upon': 149,\n",
       " 'why': 150,\n",
       " 'thing': 151,\n",
       " 'cannot': 152,\n",
       " 'art': 153,\n",
       " 'again': 154,\n",
       " 'part': 155,\n",
       " 'order': 156,\n",
       " 'gods': 157,\n",
       " 'after': 158,\n",
       " 'mind': 159,\n",
       " 'yet': 160,\n",
       " 'does': 161,\n",
       " 'nor': 162,\n",
       " 'power': 163,\n",
       " 'too': 164,\n",
       " 'neither': 165,\n",
       " 'able': 166,\n",
       " 'virtue': 167,\n",
       " 'manner': 168,\n",
       " 'whole': 169,\n",
       " 'much': 170,\n",
       " 'body': 171,\n",
       " 'use': 172,\n",
       " 'always': 173,\n",
       " 'themselves': 174,\n",
       " 'guardians': 175,\n",
       " 'go': 176,\n",
       " 'even': 177,\n",
       " 'principle': 178,\n",
       " 'might': 179,\n",
       " 'under': 180,\n",
       " 'tell': 181,\n",
       " 'friend': 182,\n",
       " 'still': 183,\n",
       " 'words': 184,\n",
       " 'rather': 185,\n",
       " 'anything': 186,\n",
       " 'pleasure': 187,\n",
       " 'each': 188,\n",
       " 'ever': 189,\n",
       " 'rulers': 190,\n",
       " 'she': 191,\n",
       " 'ask': 192,\n",
       " 'answer': 193,\n",
       " 'before': 194,\n",
       " 'speaking': 195,\n",
       " 'over': 196,\n",
       " 'clearly': 197,\n",
       " 'socrates': 198,\n",
       " 'come': 199,\n",
       " 'greatest': 200,\n",
       " 'place': 201,\n",
       " 'against': 202,\n",
       " 'class': 203,\n",
       " 'children': 204,\n",
       " 'case': 205,\n",
       " 'further': 206,\n",
       " 'agree': 207,\n",
       " 'among': 208,\n",
       " 'found': 209,\n",
       " 'world': 210,\n",
       " 'kind': 211,\n",
       " 'citizens': 212,\n",
       " 'glaucon': 213,\n",
       " 'light': 214,\n",
       " 'likely': 215,\n",
       " 'pleasures': 216,\n",
       " 'greater': 217,\n",
       " 'god': 218,\n",
       " 'honour': 219,\n",
       " 'desire': 220,\n",
       " 'give': 221,\n",
       " 'hear': 222,\n",
       " 'indeed': 223,\n",
       " 'philosophy': 224,\n",
       " 'thus': 225,\n",
       " 'sight': 226,\n",
       " 'youth': 227,\n",
       " 'less': 228,\n",
       " 'consider': 229,\n",
       " 'view': 230,\n",
       " 'did': 231,\n",
       " 'war': 232,\n",
       " 'desires': 233,\n",
       " 'away': 234,\n",
       " 'end': 235,\n",
       " 'without': 236,\n",
       " 'call': 237,\n",
       " 'money': 238,\n",
       " 'argument': 239,\n",
       " 'interest': 240,\n",
       " 'three': 241,\n",
       " 'wisdom': 242,\n",
       " 'women': 243,\n",
       " 'law': 244,\n",
       " 'education': 245,\n",
       " 'old': 246,\n",
       " 'look': 247,\n",
       " 'believe': 248,\n",
       " 'understand': 249,\n",
       " 'states': 250,\n",
       " 'spirit': 251,\n",
       " 'thrasymachus': 252,\n",
       " 'seen': 253,\n",
       " 'people': 254,\n",
       " 'imagine': 255,\n",
       " 'little': 256,\n",
       " 'else': 257,\n",
       " 'human': 258,\n",
       " 'enough': 259,\n",
       " 'while': 260,\n",
       " 'son': 261,\n",
       " 'where': 262,\n",
       " 'speak': 263,\n",
       " 'could': 264,\n",
       " 'wise': 265,\n",
       " 'love': 266,\n",
       " 'bad': 267,\n",
       " 'point': 268,\n",
       " 'persons': 269,\n",
       " 'thought': 270,\n",
       " 'natural': 271,\n",
       " 'care': 272,\n",
       " 'form': 273,\n",
       " 'work': 274,\n",
       " 'natures': 275,\n",
       " 'friends': 276,\n",
       " 'want': 277,\n",
       " 'rest': 278,\n",
       " 'become': 279,\n",
       " 'music': 280,\n",
       " 'tyrant': 281,\n",
       " 'young': 282,\n",
       " 'opposite': 283,\n",
       " 'truly': 284,\n",
       " 'number': 285,\n",
       " 'arts': 286,\n",
       " 'next': 287,\n",
       " 'together': 288,\n",
       " 'making': 289,\n",
       " 'person': 290,\n",
       " 'find': 291,\n",
       " 'proceed': 292,\n",
       " 'course': 293,\n",
       " 'present': 294,\n",
       " 'individual': 295,\n",
       " 'different': 296,\n",
       " 'common': 297,\n",
       " 'father': 298,\n",
       " 'remember': 299,\n",
       " 'surely': 300,\n",
       " 'homer': 301,\n",
       " 'put': 302,\n",
       " 'really': 303,\n",
       " 'government': 304,\n",
       " 'called': 305,\n",
       " 'eyes': 306,\n",
       " 'last': 307,\n",
       " 'pain': 308,\n",
       " 'sense': 309,\n",
       " 'fear': 310,\n",
       " 'given': 311,\n",
       " 'necessity': 312,\n",
       " 'rule': 313,\n",
       " 'although': 314,\n",
       " 'certain': 315,\n",
       " 'until': 316,\n",
       " 'already': 317,\n",
       " 'qualities': 318,\n",
       " 'third': 319,\n",
       " 'comes': 320,\n",
       " 'beauty': 321,\n",
       " 'done': 322,\n",
       " 'matter': 323,\n",
       " 'hand': 324,\n",
       " 'subject': 325,\n",
       " 'private': 326,\n",
       " 'turn': 327,\n",
       " 'change': 328,\n",
       " 'down': 329,\n",
       " 'between': 330,\n",
       " 'meaning': 331,\n",
       " 'enemies': 332,\n",
       " 'need': 333,\n",
       " 'subjects': 334,\n",
       " 'help': 335,\n",
       " 'adeimantus': 336,\n",
       " 'age': 337,\n",
       " 'drink': 338,\n",
       " 'general': 339,\n",
       " 'name': 340,\n",
       " 'makes': 341,\n",
       " 'idea': 342,\n",
       " 'within': 343,\n",
       " 'here': 344,\n",
       " 'equally': 345,\n",
       " 'stronger': 346,\n",
       " 'says': 347,\n",
       " 'rich': 348,\n",
       " 'whose': 349,\n",
       " 'word': 350,\n",
       " 'means': 351,\n",
       " 'lover': 352,\n",
       " 'real': 353,\n",
       " 'absolute': 354,\n",
       " 'temperance': 355,\n",
       " 'something': 356,\n",
       " 'doing': 357,\n",
       " 'sure': 358,\n",
       " 'though': 359,\n",
       " 'small': 360,\n",
       " 'principles': 361,\n",
       " 'difficulty': 362,\n",
       " 'death': 363,\n",
       " 'similar': 364,\n",
       " 'philosopher': 365,\n",
       " 'appear': 366,\n",
       " 'laws': 367,\n",
       " 'ruler': 368,\n",
       " 'whereas': 369,\n",
       " 'character': 370,\n",
       " 'hardly': 371,\n",
       " 'once': 372,\n",
       " 'heaven': 373,\n",
       " 'exactly': 374,\n",
       " 'begin': 375,\n",
       " 'gymnastic': 376,\n",
       " 'guardian': 377,\n",
       " 'receive': 378,\n",
       " 'lives': 379,\n",
       " 'impossible': 380,\n",
       " 'public': 381,\n",
       " 'live': 382,\n",
       " 'existence': 383,\n",
       " 'possible': 384,\n",
       " 'asked': 385,\n",
       " 'going': 386,\n",
       " 'often': 387,\n",
       " 'poets': 388,\n",
       " 'longer': 389,\n",
       " 'wealth': 390,\n",
       " 'second': 391,\n",
       " 'appears': 392,\n",
       " 'doubt': 393,\n",
       " 'instead': 394,\n",
       " 'hands': 395,\n",
       " 'eye': 396,\n",
       " 'forms': 397,\n",
       " 'science': 398,\n",
       " 'happiness': 399,\n",
       " 'worse': 400,\n",
       " 'full': 401,\n",
       " 'get': 402,\n",
       " 'lie': 403,\n",
       " 'example': 404,\n",
       " 'unless': 405,\n",
       " 'perfectly': 406,\n",
       " 'perfect': 407,\n",
       " 'day': 408,\n",
       " 'difference': 409,\n",
       " 'courage': 410,\n",
       " 'follow': 411,\n",
       " 'grow': 412,\n",
       " 'study': 413,\n",
       " 'years': 414,\n",
       " 'long': 415,\n",
       " 'medicine': 416,\n",
       " 'side': 417,\n",
       " 'taken': 418,\n",
       " 'none': 419,\n",
       " 'supposed': 420,\n",
       " 'allow': 421,\n",
       " 'pure': 422,\n",
       " 'simple': 423,\n",
       " 'object': 424,\n",
       " 'brought': 425,\n",
       " 'earth': 426,\n",
       " 'noble': 427,\n",
       " 'higher': 428,\n",
       " 'necessary': 429,\n",
       " 'beautiful': 430,\n",
       " 'told': 431,\n",
       " 'few': 432,\n",
       " 'wrong': 433,\n",
       " 'seem': 434,\n",
       " 'however': 435,\n",
       " 'according': 436,\n",
       " 'off': 437,\n",
       " 'gain': 438,\n",
       " 'health': 439,\n",
       " 'business': 440,\n",
       " 'philosophers': 441,\n",
       " 'divine': 442,\n",
       " 'imitation': 443,\n",
       " 'democracy': 444,\n",
       " 'towards': 445,\n",
       " 'poor': 446,\n",
       " 'gold': 447,\n",
       " 'enemy': 448,\n",
       " 'allowed': 449,\n",
       " 'above': 450,\n",
       " 'ready': 451,\n",
       " 'times': 452,\n",
       " 'four': 453,\n",
       " 'learn': 454,\n",
       " 'knows': 455,\n",
       " 'enquiry': 456,\n",
       " 'ignorance': 457,\n",
       " 'harmony': 458,\n",
       " 'sun': 459,\n",
       " 'fair': 460,\n",
       " 'experience': 461,\n",
       " 'poet': 462,\n",
       " 'sons': 463,\n",
       " 'reverse': 464,\n",
       " 'proper': 465,\n",
       " 'food': 466,\n",
       " 'dear': 467,\n",
       " 'came': 468,\n",
       " 'quality': 469,\n",
       " 'seeing': 470,\n",
       " 'highest': 471,\n",
       " 'described': 472,\n",
       " 'degree': 473,\n",
       " 'constitution': 474,\n",
       " 'master': 475,\n",
       " 'several': 476,\n",
       " 'happy': 477,\n",
       " 'termed': 478,\n",
       " 'wish': 479,\n",
       " 'admit': 480,\n",
       " 'required': 481,\n",
       " 'compelled': 482,\n",
       " 'vice': 483,\n",
       " 'through': 484,\n",
       " 'beyond': 485,\n",
       " 'individuals': 486,\n",
       " 'image': 487,\n",
       " 'ridiculous': 488,\n",
       " 'hold': 489,\n",
       " 'style': 490,\n",
       " 'becomes': 491,\n",
       " 'bodily': 492,\n",
       " 'term': 493,\n",
       " 'mankind': 494,\n",
       " 'least': 495,\n",
       " 'conceive': 496,\n",
       " 'set': 497,\n",
       " 'beginning': 498,\n",
       " 'show': 499,\n",
       " 'objects': 500,\n",
       " 'describing': 501,\n",
       " 'lovers': 502,\n",
       " 'polemarchus': 503,\n",
       " 'regard': 504,\n",
       " 'evils': 505,\n",
       " 'easily': 506,\n",
       " 'condition': 507,\n",
       " 'physician': 508,\n",
       " 'harm': 509,\n",
       " 'thinking': 510,\n",
       " 'reality': 511,\n",
       " 'admitted': 512,\n",
       " 'observe': 513,\n",
       " 'perhaps': 514,\n",
       " 'ways': 515,\n",
       " 'particular': 516,\n",
       " 'souls': 517,\n",
       " 'poetry': 518,\n",
       " 'imitate': 519,\n",
       " 'faculty': 520,\n",
       " 'shadows': 521,\n",
       " 'satisfied': 522,\n",
       " 'parents': 523,\n",
       " 'disease': 524,\n",
       " 'assuredly': 525,\n",
       " 'heard': 526,\n",
       " 'rightly': 527,\n",
       " 'force': 528,\n",
       " 'miserable': 529,\n",
       " 'house': 530,\n",
       " 'company': 531,\n",
       " 'property': 532,\n",
       " 'below': 533,\n",
       " 'gives': 534,\n",
       " 'result': 535,\n",
       " 'latter': 536,\n",
       " 'nay': 537,\n",
       " 'ignorant': 538,\n",
       " 'generally': 539,\n",
       " 'advantage': 540,\n",
       " 'try': 541,\n",
       " 'strength': 542,\n",
       " 'understanding': 543,\n",
       " 'pains': 544,\n",
       " 'ones': 545,\n",
       " 'maintain': 546,\n",
       " 'unable': 547,\n",
       " 'oligarchy': 548,\n",
       " 'new': 549,\n",
       " 'pass': 550,\n",
       " 'since': 551,\n",
       " 'keep': 552,\n",
       " 'easy': 553,\n",
       " 'cause': 554,\n",
       " 'peace': 555,\n",
       " 'clear': 556,\n",
       " 'act': 557,\n",
       " 'seeking': 558,\n",
       " 'yourself': 559,\n",
       " 'whatever': 560,\n",
       " 'taking': 561,\n",
       " 'authority': 562,\n",
       " 'behold': 563,\n",
       " 'learning': 564,\n",
       " 'praise': 565,\n",
       " 'everything': 566,\n",
       " 'concerned': 567,\n",
       " 'action': 568,\n",
       " 'left': 569,\n",
       " 'discovered': 570,\n",
       " 'classes': 571,\n",
       " 'effect': 572,\n",
       " 'former': 573,\n",
       " 'bring': 574,\n",
       " 'habit': 575,\n",
       " 'woman': 576,\n",
       " 'geometry': 577,\n",
       " 'turned': 578,\n",
       " 'known': 579,\n",
       " 'draw': 580,\n",
       " 'sake': 581,\n",
       " 'useful': 582,\n",
       " 'knowing': 583,\n",
       " 'silver': 584,\n",
       " 'useless': 585,\n",
       " 'agreed': 586,\n",
       " 'danger': 587,\n",
       " 'notion': 588,\n",
       " 'goes': 589,\n",
       " 'tyrannical': 590,\n",
       " 'maker': 591,\n",
       " 'takes': 592,\n",
       " 'slaves': 593,\n",
       " 'single': 594,\n",
       " 'houses': 595,\n",
       " 'kinds': 596,\n",
       " 'animals': 597,\n",
       " 'sorrow': 598,\n",
       " 'passion': 599,\n",
       " 'intermediate': 600,\n",
       " 'visible': 601,\n",
       " 'oligarchical': 602,\n",
       " 'bed': 603,\n",
       " 'round': 604,\n",
       " 'deny': 605,\n",
       " 'freedom': 606,\n",
       " 'country': 607,\n",
       " 'leave': 608,\n",
       " 'actions': 609,\n",
       " 'shown': 610,\n",
       " 'saw': 611,\n",
       " 'escape': 612,\n",
       " 'follows': 613,\n",
       " 'inferior': 614,\n",
       " 'require': 615,\n",
       " 'alone': 616,\n",
       " 'tyranny': 617,\n",
       " 'excellence': 618,\n",
       " 'false': 619,\n",
       " 'minds': 620,\n",
       " 'days': 621,\n",
       " 'upwards': 622,\n",
       " 'trained': 623,\n",
       " 'moment': 624,\n",
       " 'rhythm': 625,\n",
       " 'training': 626,\n",
       " 'element': 627,\n",
       " 'relation': 628,\n",
       " 'share': 629,\n",
       " 'pursuits': 630,\n",
       " 'gifts': 631,\n",
       " 'perceive': 632,\n",
       " 'tale': 633,\n",
       " 'bear': 634,\n",
       " 'pilot': 635,\n",
       " 'excellent': 636,\n",
       " 'seems': 637,\n",
       " 'angry': 638,\n",
       " 'ruling': 639,\n",
       " 'acknowledge': 640,\n",
       " 'mans': 641,\n",
       " 'deemed': 642,\n",
       " 'judge': 643,\n",
       " 'fight': 644,\n",
       " 'assume': 645,\n",
       " 'utterly': 646,\n",
       " 'middle': 647,\n",
       " 'strain': 648,\n",
       " 'sorts': 649,\n",
       " 'educated': 650,\n",
       " 'influence': 651,\n",
       " 'naturally': 652,\n",
       " 'spoke': 653,\n",
       " 'images': 654,\n",
       " 'home': 655,\n",
       " 'enquire': 656,\n",
       " 'feeling': 657,\n",
       " 'near': 658,\n",
       " 'tales': 659,\n",
       " 'pay': 660,\n",
       " 'back': 661,\n",
       " 'spoken': 662,\n",
       " 'alike': 663,\n",
       " 'command': 664,\n",
       " 'play': 665,\n",
       " 'account': 666,\n",
       " 'ill': 667,\n",
       " 'itself': 668,\n",
       " 'names': 669,\n",
       " 'whenever': 670,\n",
       " 'worst': 671,\n",
       " 'affirm': 672,\n",
       " 'ground': 673,\n",
       " 'suffer': 674,\n",
       " 'judgment': 675,\n",
       " 'honours': 676,\n",
       " 'describe': 677,\n",
       " 'mother': 678,\n",
       " 'painter': 679,\n",
       " 'original': 680,\n",
       " 'ourselves': 681,\n",
       " 'sees': 682,\n",
       " 'zeus': 683,\n",
       " 'parts': 684,\n",
       " 'military': 685,\n",
       " 'possibility': 686,\n",
       " 'virtues': 687,\n",
       " 'sciences': 688,\n",
       " 'received': 689,\n",
       " 'thinks': 690,\n",
       " 'child': 691,\n",
       " 'attempt': 692,\n",
       " 'duty': 693,\n",
       " 'interests': 694,\n",
       " 'sometimes': 695,\n",
       " 'mistaken': 696,\n",
       " 'respect': 697,\n",
       " 'fails': 698,\n",
       " 'its': 699,\n",
       " 'office': 700,\n",
       " 'free': 701,\n",
       " 'considered': 702,\n",
       " 'honourable': 703,\n",
       " 'carried': 704,\n",
       " 'lest': 705,\n",
       " 'gentle': 706,\n",
       " 'appearance': 707,\n",
       " 'causes': 708,\n",
       " 'dog': 709,\n",
       " 'parent': 710,\n",
       " 'attain': 711,\n",
       " 'dialectic': 712,\n",
       " 'run': 713,\n",
       " 'arrived': 714,\n",
       " 'sweet': 715,\n",
       " 'undoubtedly': 716,\n",
       " 'dogs': 717,\n",
       " 'battle': 718,\n",
       " 'discussion': 719,\n",
       " 'willing': 720,\n",
       " 'fact': 721,\n",
       " 'numbers': 722,\n",
       " 'cases': 723,\n",
       " 'payment': 724,\n",
       " 'utter': 725,\n",
       " 'conclusion': 726,\n",
       " 'discover': 727,\n",
       " 'mere': 728,\n",
       " 'wants': 729,\n",
       " 'origin': 730,\n",
       " 'hearing': 731,\n",
       " 'remains': 732,\n",
       " 'large': 733,\n",
       " 'reasons': 734,\n",
       " 'unlike': 735,\n",
       " 'please': 736,\n",
       " 'add': 737,\n",
       " 'purpose': 738,\n",
       " 'rewards': 739,\n",
       " 'liberty': 740,\n",
       " 'king': 741,\n",
       " 'dead': 742,\n",
       " 'finger': 743,\n",
       " 'cities': 744,\n",
       " 'process': 745,\n",
       " 'land': 746,\n",
       " 'especially': 747,\n",
       " 'author': 748,\n",
       " 'matters': 749,\n",
       " 'previous': 750,\n",
       " 'lot': 751,\n",
       " 'meet': 752,\n",
       " 'harmonies': 753,\n",
       " 'drawn': 754,\n",
       " 'equal': 755,\n",
       " 'intelligence': 756,\n",
       " 'proportion': 757,\n",
       " 'hellenes': 758,\n",
       " 'measure': 759,\n",
       " 'thirst': 760,\n",
       " 'division': 761,\n",
       " 'pursuit': 762,\n",
       " 'distance': 763,\n",
       " 'coming': 764,\n",
       " 'listen': 765,\n",
       " 'soon': 766,\n",
       " 'journey': 767,\n",
       " 'fault': 768,\n",
       " 'answered': 769,\n",
       " 'possess': 770,\n",
       " 'profit': 771,\n",
       " 'possession': 772,\n",
       " 'sacrifices': 773,\n",
       " 'probably': 774,\n",
       " 'giving': 775,\n",
       " 'guilty': 776,\n",
       " 'mistake': 777,\n",
       " 'myself': 778,\n",
       " 'weaker': 779,\n",
       " 'absolutely': 780,\n",
       " 'liable': 781,\n",
       " 'contrary': 782,\n",
       " 'fail': 783,\n",
       " 'deal': 784,\n",
       " 'got': 785,\n",
       " 'entirely': 786,\n",
       " 'ideas': 787,\n",
       " 'getting': 788,\n",
       " 'ears': 789,\n",
       " 'choose': 790,\n",
       " 'incapable': 791,\n",
       " 'unity': 792,\n",
       " 'explain': 793,\n",
       " 'necessarily': 794,\n",
       " 'practise': 795,\n",
       " 'arise': 796,\n",
       " 'lead': 797,\n",
       " 'along': 798,\n",
       " 'continue': 799,\n",
       " 'fourth': 800,\n",
       " 'water': 801,\n",
       " 'husbandman': 802,\n",
       " 'motion': 803,\n",
       " 'destroy': 804,\n",
       " 'elements': 805,\n",
       " 'aware': 806,\n",
       " 'imitator': 807,\n",
       " 'fall': 808,\n",
       " 'soldiers': 809,\n",
       " 'strange': 810,\n",
       " 'sphere': 811,\n",
       " 'fathers': 812,\n",
       " 'terms': 813,\n",
       " 'essence': 814,\n",
       " 'wives': 815,\n",
       " 'notbeing': 816,\n",
       " 'offer': 817,\n",
       " 'took': 818,\n",
       " 'persuade': 819,\n",
       " 'carry': 820,\n",
       " 'head': 821,\n",
       " 'difficult': 822,\n",
       " 'feel': 823,\n",
       " 'fortune': 824,\n",
       " 'hence': 825,\n",
       " 'begins': 826,\n",
       " 'hope': 827,\n",
       " 'occasion': 828,\n",
       " 'greatly': 829,\n",
       " 'advantages': 830,\n",
       " 'o': 831,\n",
       " 'meant': 832,\n",
       " 'musician': 833,\n",
       " 'benefit': 834,\n",
       " 'clearness': 835,\n",
       " 'hard': 836,\n",
       " 'answers': 837,\n",
       " 'dare': 838,\n",
       " 'notions': 839,\n",
       " 'acknowledged': 840,\n",
       " 'artist': 841,\n",
       " 'distinguished': 842,\n",
       " 'blessed': 843,\n",
       " 'fairly': 844,\n",
       " 'passed': 845,\n",
       " 'proof': 846,\n",
       " 'began': 847,\n",
       " 'special': 848,\n",
       " 'laid': 849,\n",
       " 'trouble': 850,\n",
       " 'charming': 851,\n",
       " 'profitable': 852,\n",
       " 'rate': 853,\n",
       " 'creature': 854,\n",
       " 'exist': 855,\n",
       " 'army': 856,\n",
       " 'appointed': 857,\n",
       " 'lost': 858,\n",
       " 'apply': 859,\n",
       " 'taste': 860,\n",
       " 'voice': 861,\n",
       " 'honoured': 862,\n",
       " 'service': 863,\n",
       " 'wonder': 864,\n",
       " 'likeness': 865,\n",
       " 'dream': 866,\n",
       " 'vision': 867,\n",
       " 'courageous': 868,\n",
       " 'carpenter': 869,\n",
       " 'kings': 870,\n",
       " 'slave': 871,\n",
       " 'nearly': 872,\n",
       " 'discord': 873,\n",
       " 'corruption': 874,\n",
       " 'passionate': 875,\n",
       " 'ruin': 876,\n",
       " 'upper': 877,\n",
       " 'community': 878,\n",
       " 'figure': 879,\n",
       " 'appeared': 880,\n",
       " 'remain': 881,\n",
       " 'refuse': 882,\n",
       " 'horses': 883,\n",
       " 'convinced': 884,\n",
       " 'famous': 885,\n",
       " 'reply': 886,\n",
       " 'reflect': 887,\n",
       " 'arms': 888,\n",
       " 'return': 889,\n",
       " 'senses': 890,\n",
       " 'bodies': 891,\n",
       " 'guard': 892,\n",
       " 'expected': 893,\n",
       " 'wild': 894,\n",
       " 'beast': 895,\n",
       " 'fixed': 896,\n",
       " 'length': 897,\n",
       " 'wholly': 898,\n",
       " 'democratical': 899,\n",
       " 'remark': 900,\n",
       " 'used': 901,\n",
       " 'skill': 902,\n",
       " 'questions': 903,\n",
       " 'future': 904,\n",
       " 'superior': 905,\n",
       " 'provide': 906,\n",
       " 'aim': 907,\n",
       " 'perfection': 908,\n",
       " 'fancy': 909,\n",
       " 'learned': 910,\n",
       " 'determine': 911,\n",
       " 'lesser': 912,\n",
       " 'assent': 913,\n",
       " 'various': 914,\n",
       " 'held': 915,\n",
       " 'knew': 916,\n",
       " 'serious': 917,\n",
       " 'goods': 918,\n",
       " 'judges': 919,\n",
       " 'strong': 920,\n",
       " 'earnest': 921,\n",
       " 'otherwise': 922,\n",
       " 'choice': 923,\n",
       " 'relative': 924,\n",
       " 'quarrel': 925,\n",
       " 'family': 926,\n",
       " 'except': 927,\n",
       " 'blind': 928,\n",
       " 'misery': 929,\n",
       " 'passing': 930,\n",
       " 'reputation': 931,\n",
       " 'worthy': 932,\n",
       " 'chosen': 933,\n",
       " 'becoming': 934,\n",
       " 'heavens': 935,\n",
       " 'forth': 936,\n",
       " 'living': 937,\n",
       " 'numerous': 938,\n",
       " 'heroes': 939,\n",
       " 'afraid': 940,\n",
       " 'offspring': 941,\n",
       " 'larger': 942,\n",
       " 'mention': 943,\n",
       " 'labour': 944,\n",
       " 'multitude': 945,\n",
       " 'warrior': 946,\n",
       " 'duties': 947,\n",
       " 'spirited': 948,\n",
       " 'gymnastics': 949,\n",
       " 'external': 950,\n",
       " 'circumstances': 951,\n",
       " 'fairest': 952,\n",
       " 'temperate': 953,\n",
       " 'habits': 954,\n",
       " 'asclepius': 955,\n",
       " 'happen': 956,\n",
       " 'ideal': 957,\n",
       " 'holds': 958,\n",
       " 'legislator': 959,\n",
       " 'appetites': 960,\n",
       " 'akin': 961,\n",
       " 'birth': 962,\n",
       " 'hypotheses': 963,\n",
       " 'remaining': 964,\n",
       " 'direction': 965,\n",
       " 'servant': 966,\n",
       " 'brother': 967,\n",
       " 'commonly': 968,\n",
       " 'suspect': 969,\n",
       " 'besides': 970,\n",
       " 'expect': 971,\n",
       " 'sum': 972,\n",
       " 'sleep': 973,\n",
       " 'debt': 974,\n",
       " 'amid': 975,\n",
       " 'inference': 976,\n",
       " 'argue': 977,\n",
       " 'utmost': 978,\n",
       " 'avoid': 979,\n",
       " 'obey': 980,\n",
       " 'sailors': 981,\n",
       " 'exercise': 982,\n",
       " 'suitable': 983,\n",
       " 'taught': 984,\n",
       " 'shepherd': 985,\n",
       " 'scale': 986,\n",
       " 'ambitious': 987,\n",
       " 'task': 988,\n",
       " 'propose': 989,\n",
       " 'practice': 990,\n",
       " 'disposed': 991,\n",
       " 'freemen': 992,\n",
       " 'accomplished': 993,\n",
       " 'deprived': 994,\n",
       " 'assigned': 995,\n",
       " 'watch': 996,\n",
       " 'iron': 997,\n",
       " 'step': 998,\n",
       " 'hour': 999,\n",
       " 'lying': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7409"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  11, 1045,  329, ...,   11,   57, 1265],\n",
       "       [1045,  329, 7409, ...,   57, 1265,   35],\n",
       "       [ 329, 7409,    4, ..., 1265,   35,    1],\n",
       "       ...,\n",
       "       [ 382,  467,    4, ..., 1044,  414,   13],\n",
       "       [ 467,    4,   33, ...,  414,   13,   21],\n",
       "       [   4,   33,   79, ...,   13,   21,   23]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118631, 50)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  35,    1, 2874, ...,   21,   23,   85])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 50, 50)            370500    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7410)              748410    \n",
      "=================================================================\n",
      "Total params: 1,269,810\n",
      "Trainable params: 1,269,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "118631/118631 [==============================] - 152s 1ms/step - loss: 6.1660 - acc: 0.0688\n",
      "Epoch 2/2\n",
      "118631/118631 [==============================] - 144s 1ms/step - loss: 5.7354 - acc: 0.1021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1079e5438>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'republic_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the text so that we can choose a source sequence as input to the model for generating a new sequence \n",
    "# of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very true he replied yet having begun we must go forward to the rough places of the law at the same time begging of these gentlemen for once in their life to be serious not long ago as we shall remind them the hellenes were of the opinion which is still\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded = tokenizer.texts_to_sequences([seed_text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of the state of\n"
     ]
    }
   ],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)\n",
    " \n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text,40)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
